{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow's Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary import\n",
    "import pandas as pd\n",
    "import mlflow, pickle\n",
    "from datetime import datetime\n",
    "from mlflow.entities import ViewType\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "# Set the mlflow unique resource idenitifier - can be the url of a remote server\n",
    "MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interacting with the MLflow tracking server\n",
    "\n",
    "The `MlflowClient` object allows us to interact with:\n",
    "- an MLflow Tracking Server that creates and manages experiments and runs.\n",
    "- an MLflow Registry Server that creates and manages registered models and model versions. \n",
    "\n",
    "To instantiate it we need to pass a tracking URI and/or a registry URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='/Users/cm-mboulou-mac/Dvt/MLOps-Zoomcamp-2025/02_experiment-tracking/notebooks/course/mlruns/1', creation_time=1748145819474, experiment_id='1', last_update_time=1748145819474, lifecycle_stage='active', name='nyc-taxi-experiment', tags={}>,\n",
       " <Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1748145792148, experiment_id='0', last_update_time=1748145792148, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate an mlflow client\n",
    "client = MlflowClient(tracking_uri = MLFLOW_TRACKING_URI)\n",
    "\n",
    "# Get the list of ML experiments\n",
    "client.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create another experiment\n",
    "client.create_experiment(name = \"my-cool-experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the latest versions for the experiment with id `1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for runs\n",
    "runs = client.search_runs(\n",
    "    experiment_ids = '1',\n",
    "    filter_string = \"metrics.rmse < 7\",\n",
    "    run_view_type = ViewType.ACTIVE_ONLY, # to keep only active runs, excluding deleted ones\n",
    "    max_results = 5,\n",
    "    order_by = [\"metrics.rmse ASC\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: 5ed38d6110a1443c8fa388f14adc1c76, rmse: 6.3087\n",
      "run id: b15f56ed70914fc7980e4d4b547ee569, rmse: 6.7423\n",
      "run id: a5313a19f9ba49aebd19bc8603e6f28c, rmse: 6.9096\n",
      "run id: 1edaced899854f70a77a4d24ec146c4b, rmse: 6.9225\n"
     ]
    }
   ],
   "source": [
    "# For each exoeriment run\n",
    "for run in runs:\n",
    "    # Print the id and the metrics\n",
    "    print(f\"run id: {run.info.run_id}, rmse: {run.data.metrics['rmse']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interacting with the Model Registry\n",
    "\n",
    "In this section We will use the `MlflowClient` instance to:\n",
    "\n",
    "1. Register a new version for the experiment `nyc-taxi-regressor`\n",
    "2. Retrieve the latests versions of the model `nyc-taxi-regressor` and check that a new version `4` was created.\n",
    "3. Transition the version `4` to \"Staging\" and adding annotations to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the tracking server\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'nyc-taxi-regressor' already exists. Creating a new version of this model...\n",
      "Created version '4' of model 'nyc-taxi-regressor'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1748170836107, current_stage='None', description=None, last_updated_timestamp=1748170836107, name='nyc-taxi-regressor', run_id='a5313a19f9ba49aebd19bc8603e6f28c', run_link=None, source='/Users/cm-mboulou-mac/Dvt/MLOps-Zoomcamp-2025/02_experiment-tracking/notebooks/course/mlruns/1/a5313a19f9ba49aebd19bc8603e6f28c/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=4>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment run id\n",
    "run_id = \"a5313a19f9ba49aebd19bc8603e6f28c\"\n",
    "# Model URI\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "# Model name\n",
    "model_name = \"nyc-taxi-regressor\"\n",
    "# Register a model\n",
    "mlflow.register_model(model_uri = model_uri, name = model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: 4, stage: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bc/8szymj2165x0w0nswg6k79xc0000gn/T/ipykernel_27389/4136139139.py:3: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  latest_versions = client.get_latest_versions(name = model_name)\n"
     ]
    }
   ],
   "source": [
    "# Get the latest versions of the nyc-taxi-regressor model\n",
    "latest_versions = client.get_latest_versions(name = model_name)\n",
    "\n",
    "# For each last version of the model\n",
    "for version in latest_versions:\n",
    "    # Prints the version and the stage\n",
    "    print(f\"version: {version.version}, stage: {version.current_stage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we only have one model here as we couldn't stage models using the interface. This can still be done via code but is deprecated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bc/8szymj2165x0w0nswg6k79xc0000gn/T/ipykernel_27389/256214788.py:6: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1748163398233, current_stage='Production', description='', last_updated_timestamp=1748171834425, name='nyc-taxi-regressor', run_id='5ed38d6110a1443c8fa388f14adc1c76', run_link='', source='/Users/cm-mboulou-mac/Dvt/MLOps-Zoomcamp-2025/02_experiment-tracking/notebooks/course/mlruns/1/5ed38d6110a1443c8fa388f14adc1c76/artifacts/models_mlflow', status='READY', status_message=None, tags={'model': 'xgboost'}, user_id=None, version=2>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model version\n",
    "model_version = 2 # note originally we updated the version 4, and then 1\n",
    "# Set new stage\n",
    "new_stage = \"Production\" # other versions stayed in staging stage\n",
    "# Transition model from development to staging\n",
    "client.transition_model_version_stage(\n",
    "    name = model_name,\n",
    "    version = model_version,\n",
    "    stage = new_stage,\n",
    "    archive_existing_versions = True # other versions were not archived \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1748163398233, current_stage='Production', description='The model version 2 was transitioned to Production on 2025-05-25.', last_updated_timestamp=1748172163949, name='nyc-taxi-regressor', run_id='5ed38d6110a1443c8fa388f14adc1c76', run_link='', source='/Users/cm-mboulou-mac/Dvt/MLOps-Zoomcamp-2025/02_experiment-tracking/notebooks/course/mlruns/1/5ed38d6110a1443c8fa388f14adc1c76/artifacts/models_mlflow', status='READY', status_message=None, tags={'model': 'xgboost'}, user_id=None, version=2>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get today's date\n",
    "date = datetime.today().date()\n",
    "# Update the model's decription by its version (here with the model v2)\n",
    "client.update_model_version(\n",
    "    name = model_name,\n",
    "    version = model_version,\n",
    "    description = f\"The model version {model_version} was transitioned to {new_stage} on {date}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing versions and selecting the new \"Production\" model\n",
    "\n",
    "In the last section, we will retrieve models registered in the model registry and compare their performance on an unseen test set. The idea is to simulate the scenario in which a deployment engineer has to interact with the model registry to decide whether to update the model version that is in production or not.\n",
    "\n",
    "These are the steps:\n",
    "\n",
    "1. Load the test dataset, which corresponds to the NYC Green Taxi data from the month of March 2021.\n",
    "2. Download the `DictVectorizer` that was fitted using the training data and saved to MLflow as an artifact, and load it with pickle.\n",
    "3. Preprocess the test set using the `DictVectorizer` so we can properly feed the regressors.\n",
    "4. Make predictions on the test set using the model versions that are currently in the \"Staging\" and \"Production\" stages, and compare their performance.\n",
    "5. Based on the results, update the \"Production\" model version accordingly.\n",
    "\n",
    "\n",
    "**Note: the model registry doesn't actually deploy the model to production when you transition a model to the \"Production\" stage, it just assign a label to that model version. You should complement the registry with some CI/CD code that does the actual deployment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for wrangling the data\n",
    "def read_dataframe(filename):\n",
    "    # If the data is a csv file\n",
    "    if filename.endswith('.csv'):\n",
    "        # Read csv\n",
    "        df = pd.read_csv(filename)\n",
    "        # Convert to datetime\n",
    "        df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "        df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "    # else if it is a parquet file\n",
    "    elif filename.endswith('.parquet'):\n",
    "        # read parquet\n",
    "        df = pd.read_parquet(filename)\n",
    "    # Not considered file type\n",
    "    else:\n",
    "        print(\"File not supported\") # error message\n",
    "\n",
    "    # Feature Engineering\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime # target var\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60) # for minutes\n",
    "    # Filtering durations\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    # Categorical features selection\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str) # convert integers to string\n",
    "\n",
    "    # return the dataframe\n",
    "    return df\n",
    "\n",
    "# Function to preprocess the data\n",
    "def preprocess(df, dv):\n",
    "    # Get the trajet column\n",
    "    df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
    "    # Features selection\n",
    "    categorical = ['PU_DO'] # categorical\n",
    "    numerical = ['trip_distance'] # numerical\n",
    "    # Train data dictionaries\n",
    "    train_dicts = df[categorical + numerical].to_dict(orient = 'records')\n",
    "    # return preprocessed data\n",
    "    return dv.transform(train_dicts)\n",
    "\n",
    "# Function to test the model\n",
    "def test_model(name, stage, X_test, y_test):\n",
    "    # Load the model\n",
    "    model = mlflow.pyfunc.load_model(f\"models:/{name}/{stage}\")\n",
    "    # Make a prediction\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Return the RMSE\n",
    "    return {\"rmse\": root_mean_squared_error(y_test, y_pred)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the [March dataset](curl -O \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-03.parquet\") has been downloaded using the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = read_dataframe(\"data/green_tripdata_2021-03.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96dd7c90011042e4b390528c165b361e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/Users/cm-mboulou-mac/Dvt/MLOps-Zoomcamp-2025/02_experiment-tracking/notebooks/course/preprocessor'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the encoder - we used one preprocessor so no need to check for the right id\n",
    "client.download_artifacts(run_id = run_id, path ='preprocessor', dst_path = '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the encoder file\n",
    "with open(\"preprocessor/preprocessor.b\", \"rb\") as f_in:\n",
    "    # Get the encoder model\n",
    "    dv = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the testing data\n",
    "X_test = preprocess(df, dv)\n",
    "\n",
    "# Target variable\n",
    "target = \"duration\"\n",
    "# Real target values\n",
    "y_test = df[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.4 s, sys: 205 ms, total: 24.6 s\n",
      "Wall time: 3.58 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rmse': 6.256345322997512}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time test_model(name = model_name, stage = \"Production\", X_test = X_test, y_test = y_test) # test model in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.82 s, sys: 247 ms, total: 6.07 s\n",
      "Wall time: 6.27 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rmse': 6.885693344710411}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time test_model(name = model_name, stage = \"Staging\", X_test = X_test, y_test = y_test) # test model in staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model can be transitioned as Production as followed:\n",
    "# client.transition_model_version_stage(\n",
    "#     name = model_name,\n",
    "#     version = 4,\n",
    "#     stage = \"Production\",\n",
    "#     archive_existing_versions = True\n",
    "# )\n",
    "# If the performaned was similar to the optimal we would have done that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0848c9d6c7d415ad6c477ff7ff8e98694d1a4aa96d0deee89244642e6b630036"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
