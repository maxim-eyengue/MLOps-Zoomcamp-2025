{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d148437a-6394-4876-82ae-975fa14f34fd",
   "metadata": {},
   "source": [
    "# Predict Taxi Trip Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2bd82d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.18\n"
     ]
    }
   ],
   "source": [
    "# Necessary import\n",
    "import pickle\n",
    "import mlflow # for experiment tracking\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from pathlib import Path\n",
    "\n",
    "# Python version\n",
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18619e30-d559-4de7-aced-9df1664560ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1749675070001, experiment_id='1', last_update_time=1749675070001, lifecycle_stage='active', name='nyc-taxi-experiment', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the tracking uri\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\") # where metadata are stored\n",
    "# Set the experiment (creating it if doesn't exist)\n",
    "mlflow.set_experiment(\"nyc-taxi-experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9e6479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for wrangling the data\n",
    "def read_dataframe(filename):\n",
    "    # If the data is a csv file\n",
    "    if filename.endswith('.csv'):\n",
    "        # Read csv\n",
    "        df = pd.read_csv(filename)\n",
    "        # Convert to datetime\n",
    "        df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "        df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "    # else if it is a parquet file\n",
    "    elif filename.endswith('.parquet'):\n",
    "        # read parquet\n",
    "        df = pd.read_parquet(filename)\n",
    "    # Not considered file type\n",
    "    else:\n",
    "        print(\"File not supported\") # error message\n",
    "\n",
    "    # Feature Engineering\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime # target var\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60) # for minutes\n",
    "    # Filtering durations\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    # Categorical features selection\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str) # convert integers to string\n",
    "\n",
    "    # Feature Engineering to combine taxi trips origine and destination\n",
    "    df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
    "\n",
    "    # return the dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8029eba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73908, 61921)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the train and validation sets\n",
    "df_train = read_dataframe('./data/green_tripdata_2021-01.parquet') # train\n",
    "# using the url: df_train = read_dataframe('https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-01.parquet') \n",
    "df_val = read_dataframe('./data/green_tripdata_2021-02.parquet') # validation\n",
    "# using the url: df_val = read_dataframe('https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-02.parquet')\n",
    "\n",
    "# Data size\n",
    "len(df_train), len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "951d51ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set feature variables\n",
    "categorical = ['PU_DO'] #'PULocationID', 'DOLocationID\n",
    "numerical = ['trip_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5cbfc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize one-hot encoder\n",
    "dv = DictVectorizer()\n",
    "\n",
    "# Train data dictionaries\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient = 'records')\n",
    "# Encoder training\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "# Validation data dictionaries\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient = 'records')\n",
    "# Validation data encoding\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e9fb68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target variables\n",
    "target = 'duration'\n",
    "# Train and validation target vectors\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5a952a-f368-48e5-9a56-e80f20b091da",
   "metadata": {},
   "source": [
    "## Saving an XG-Boost model With MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4adaa52c-9ada-4ccf-987c-d3e25c6512f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path for saving models\n",
    "models_folder = Path('models')\n",
    "# Create the models folder\n",
    "models_folder.mkdir(exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db4ca963-3954-4270-8aeb-4667923894b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable autolog\n",
    "mlflow.xgboost.autolog(disable = True) # You can use autolog to automatically  log some information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "051bb243-0a2d-497b-84e9-4ee79346856c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mlops-zoomcamp/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [23:00:09] WARNING: /Users/runner/work/xgboost/xgboost/src/objective/regression_obj.cu:227: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:11.44482\n",
      "[1]\tvalidation-rmse:10.77202\n",
      "[2]\tvalidation-rmse:10.18363\n",
      "[3]\tvalidation-rmse:9.67396\n",
      "[4]\tvalidation-rmse:9.23166\n",
      "[5]\tvalidation-rmse:8.84808\n",
      "[6]\tvalidation-rmse:8.51883\n",
      "[7]\tvalidation-rmse:8.23597\n",
      "[8]\tvalidation-rmse:7.99320\n",
      "[9]\tvalidation-rmse:7.78709\n",
      "[10]\tvalidation-rmse:7.61022\n",
      "[11]\tvalidation-rmse:7.45952\n",
      "[12]\tvalidation-rmse:7.33049\n",
      "[13]\tvalidation-rmse:7.22098\n",
      "[14]\tvalidation-rmse:7.12713\n",
      "[15]\tvalidation-rmse:7.04752\n",
      "[16]\tvalidation-rmse:6.98005\n",
      "[17]\tvalidation-rmse:6.92232\n",
      "[18]\tvalidation-rmse:6.87112\n",
      "[19]\tvalidation-rmse:6.82740\n",
      "[20]\tvalidation-rmse:6.78995\n",
      "[21]\tvalidation-rmse:6.75792\n",
      "[22]\tvalidation-rmse:6.72994\n",
      "[23]\tvalidation-rmse:6.70547\n",
      "[24]\tvalidation-rmse:6.68390\n",
      "[25]\tvalidation-rmse:6.66421\n",
      "[26]\tvalidation-rmse:6.64806\n",
      "[27]\tvalidation-rmse:6.63280\n",
      "[28]\tvalidation-rmse:6.61924\n",
      "[29]\tvalidation-rmse:6.60773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mlops-zoomcamp/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [23:00:14] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\u001b[31m2025/06/11 23:00:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run classy-goat-254 at: http://127.0.0.1:5000/#/experiments/1/runs/57937787c7a14831aa88b8982e5d16ce\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# Start a new experiment run\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Prepare the data with XG-Boost special format\n",
    "    train = xgb.DMatrix(X_train, label = y_train) # train\n",
    "    valid = xgb.DMatrix(X_val, label = y_val) # val\n",
    "\n",
    "    # XG-Boost Model optimal parameters\n",
    "    best_params = {\n",
    "        'learning_rate': 0.09585355369315604,\n",
    "        'max_depth': 30,\n",
    "        'min_child_weight': 1.060597050922164,\n",
    "        'objective': 'reg:linear',\n",
    "        'reg_alpha': 0.018060244040060163,\n",
    "        'reg_lambda': 0.011658731377413597,\n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "    # Log the model parameters\n",
    "    mlflow.log_params(best_params) # many parameters at once\n",
    "\n",
    "    # Model training\n",
    "    booster = xgb.train(\n",
    "        params = best_params,\n",
    "        dtrain = train,\n",
    "        num_boost_round = 30,\n",
    "        evals = [(valid, 'validation')],\n",
    "        early_stopping_rounds = 50\n",
    "    )\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = booster.predict(valid)\n",
    "    # Compute the RMSE\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    # Log the model metric\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # Write a new binary file in the models folder\n",
    "    with open(\"models/preprocessor.b\", \"wb\") as f_out:\n",
    "        # Save the encoder to that file\n",
    "        pickle.dump(dv, f_out)\n",
    "    # Log the encoder file as preprocessor\n",
    "    mlflow.log_artifact(\"models/preprocessor.b\", artifact_path = \"preprocessor\")\n",
    "\n",
    "    # Log the XG-Boost model\n",
    "    mlflow.xgboost.log_model(booster, artifact_path = \"models_mlflow\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe848fbd",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
